{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b85478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"pandoc-api-version\":[1,23,1],\"meta\":{},\"blocks\":[{\"t\":\"Header\",\"c\":[2,[\"l1\",[],[]],[{\"t\":\"Str\",\"c\":\"L1\"}]]},{\"t\":\"Para\",\"c\":[{\"t\":\"Str\",\"c\":\"Hhjsdkjjkhkjhkskhjkjcd\"}]},{\"t\":\"Header\",\"c\":[2,[\"l2\",[],[]],[{\"t\":\"Str\",\"c\":\"L2\"}]]},{\"t\":\"Para\",\"c\":[{\"t\":\"Str\",\"c\":\"H;kdsclosclukhdscjducsughujsdackjdscuxshz\"}]}]}\n",
      "\n",
      "Doc\n",
      "\n",
      "List of image URLs:\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pypandoc\n",
    "import panflute\n",
    "\n",
    "def prepare (doc):\n",
    "\tdoc.images = []\n",
    "\tdoc.links = []\n",
    "\n",
    "\n",
    "\n",
    "def action(elem, doc):\n",
    "    if isinstance(elem, panflute.Image):\n",
    "        doc.images.append(elem)\n",
    "    elif isinstance(elem, panflute.Link):\n",
    "        doc.links.append(elem)\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    data = pypandoc.convert_file('sample.md', 'json')\n",
    "    print (data)\n",
    "    doc = panflute.load(io.StringIO(data))\n",
    "    print (doc)\n",
    "    doc.images = []\n",
    "    doc.links = []\n",
    "    doc = panflute.run_filter(action, prepare=prepare, doc=doc)\n",
    "\n",
    "    print(\"\\nList of image URLs:\")\n",
    "    for image in doc.images:\n",
    "        print(image.url)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea294943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 id=\"l1\">\n",
      " L1\n",
      "</h2>\n",
      "<p>\n",
      " Hhjsdkjjkhkjhkskhjkjcd\n",
      "</p>\n",
      "<h2 id=\"l2\">\n",
      " L2\n",
      "</h2>\n",
      "<p>\n",
      " H;kdsclosclukhdscjducsughujsdackjdscuxshz\n",
      "</p>\n",
      "<h2 id=\"l3\">\n",
      " L3\n",
      "</h2>\n",
      "<p>\n",
      " Vhjhkdfhudfuiudfdfvdxfbfddfzgxdghfcxbg\n",
      "</p>\n",
      "<h2 id=\"l4\">\n",
      " L4\n",
      "</h2>\n",
      "<p>\n",
      " Chujsdfijikszdijsiodoijsidiujfhusdvhu\n",
      "</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "data = pypandoc.convert_file (\"sample.md\", \"html\")\n",
    "soup = bs (data, \"html.parser\")\n",
    "\n",
    "print (soup.prettify ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bc37242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>Hhjsdkjjkhkjhkskhjkjcd</p>, <p>H;kdsclosclukhdscjducsughujsdackjdscuxshz</p>, <p>Vhjhkdfhudfuiudfdfvdxfbfddfzgxdghfcxbg</p>, <p>Chujsdfijikszdijsiodoijsidiujfhusdvhu</p>]\n",
      "\n",
      "Hhjsdkjjkhkjhkskhjkjcd\n",
      "\n",
      "H;kdsclosclukhdscjducsughujsdackjdscuxshz\n",
      "\n",
      "Vhjhkdfhudfuiudfdfvdxfbfddfzgxdghfcxbg\n",
      "\n",
      "Chujsdfijikszdijsiodoijsidiujfhusdvhu\n"
     ]
    }
   ],
   "source": [
    "tagL1 = soup.find_all (\"p\")\n",
    "print (tagL1)\n",
    "#print (tagL1.attrs)\n",
    "\n",
    "for each in tagL1:\n",
    "    print (f\"\\n{each.string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3517812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head: L1; Text: Hhjsdkjjkhkjhkskhjkjcd\n",
      "Head: L2; Text: H;kdsclosclukhdscjducsughujsdackjdscuxshz\n",
      "Head: L3; Text: Vhjhkdfhudfuiudfdfvdxfbfddfzgxdghfcxbg\n",
      "Head: L4; Text: Chujsdfijikszdijsiodoijsidiujfhusdvhu\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "data = pypandoc.convert_file (\"sample.md\", \"html\")\n",
    "soup = bs (data, \"html.parser\")\n",
    "\n",
    "head = soup.find_all (\"h2\")\n",
    "text = soup.find_all (\"p\")\n",
    "\n",
    "op = open (\"op.md\", \"w\")\n",
    "\n",
    "for i, j in zip (head, text):\n",
    "    print (f\"Head: {i.string}; Text: {j.string}\")\n",
    "    op.write (f\"## {i.string}\\n\")\n",
    "    op.write (f\"{j.string}\\n\\n\")\n",
    "    \n",
    "op.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b613cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOOGLE_APPLICATION_CREDENTIALS=\"/home/ansarimn/Downloads/DA/optimum-task-411411-3f4dc520069f.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "005f7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model:  The efficient-market hypothesis (EMH) states that asset prices reflect all available information and market prices should only react to new information. It provides the basis for modern risk-based theories of asset prices and is often associated with Eugene Fama.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The efficient-market hypothesis (EMH) states that asset prices reflect all available information and market prices should only react to new information. It provides the basis for modern risk-based theories of asset prices and is often associated with Eugene Fama.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "\n",
    "def text_summarization(\n",
    "    temperature: float,\n",
    "    project_id: str,\n",
    "    location: str,\n",
    ") -> str:\n",
    "    \"\"\"Summarization Example with a Large Language Model\"\"\"\n",
    "\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    # TODO developer - override these parameters as needed:\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
    "        \"max_output_tokens\": 256,  # Token limit determines the maximum amount of text output.\n",
    "        \"top_p\": 0.95,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "        \"top_k\": 40,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "    response = model.predict(\n",
    "        \"\"\"Provide a summary with about two sentences for the following article:\n",
    "The efficient-market hypothesis (EMH) is a hypothesis in financial \\\n",
    "economics that states that asset prices reflect all available \\\n",
    "information. A direct implication is that it is impossible to \\\n",
    "\"beat the market\" consistently on a risk-adjusted basis since market \\\n",
    "prices should only react to new information. Because the EMH is \\\n",
    "formulated in terms of risk adjustment, it only makes testable \\\n",
    "predictions when coupled with a particular model of risk. As a \\\n",
    "result, research in financial economics since at least the 1990s has \\\n",
    "focused on market anomalies, that is, deviations from specific \\\n",
    "models of risk. The idea that financial market returns are difficult \\\n",
    "to predict goes back to Bachelier, Mandelbrot, and Samuelson, but \\\n",
    "is closely associated with Eugene Fama, in part due to his \\\n",
    "influential 1970 review of the theoretical and empirical research. \\\n",
    "The EMH provides the basic logic for modern risk-based theories of \\\n",
    "asset prices, and frameworks such as consumption-based asset pricing \\\n",
    "and intermediary asset pricing can be thought of as the combination \\\n",
    "of a model of risk with the EMH. Many decades of empirical research \\\n",
    "on return predictability has found mixed evidence. Research in the \\\n",
    "1950s and 1960s often found a lack of predictability (e.g. Ball and \\\n",
    "Brown 1968; Fama, Fisher, Jensen, and Roll 1969), yet the \\\n",
    "1980s-2000s saw an explosion of discovered return predictors (e.g. \\\n",
    "Rosenberg, Reid, and Lanstein 1985; Campbell and Shiller 1988; \\\n",
    "Jegadeesh and Titman 1993). Since the 2010s, studies have often \\\n",
    "found that return predictability has become more elusive, as \\\n",
    "predictability fails to work out-of-sample (Goyal and Welch 2008), \\\n",
    "or has been weakened by advances in trading technology and investor \\\n",
    "learning (Chordia, Subrahmanyam, and Tong 2014; McLean and Pontiff \\\n",
    "2016; Martineau 2021).\n",
    "Summary:\n",
    "\"\"\",\n",
    "        **parameters,\n",
    "    )\n",
    "    print(f\"Response from Model: {response.text}\")\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "text_summarization (0.9, \"optimum-task-411411\", \"us-west1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e15a912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response is:  Bonsoir, à bientôt !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " Bonsoir, à bientôt !"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "def summ (text):\n",
    "    project_id = \"optimum-task-411411\"\n",
    "    location = \"us-west1\"\n",
    "    \n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    \n",
    "    parameters = {\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_output_tokens\": 256,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 40,\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "    \n",
    "    #j = \"Bonsoir, a bientot\"\n",
    "    \n",
    "    response = model.predict (text, **parameters)\n",
    "    \n",
    "    print (f\"Response is: {response.text}\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "data = pypandoc.convert_file (\"sample.md\", \"html\")\n",
    "soup = bs (data, \"html.parser\")\n",
    "\n",
    "head = soup.find_all (\"h2\")\n",
    "text = soup.find_all (\"p\")\n",
    "\n",
    "op = open (\"op.md\", \"w\")\n",
    "\n",
    "for i, j in zip (head, text):\n",
    "    op.write (f\"## {i.string}\\n\")\n",
    "    \n",
    "    res = summ (j.string)\n",
    "    op.write (f\"{res.text}\\n\\n\")\n",
    "    \n",
    "op.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce749d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
